
        {
            "cells": [
          {
           "cell_type": "markdown",
           "metadata": {},
           
           "source": ["// can\u0027t yet format YamlFrontmatter ([\"title: Classifying Earnings Calls with Naive Bayes\"; \"category: Scripts\"; \"categoryindex: 3\"; \"index: 3\"], Some { StartLine = 2 StartColumn = 0 EndLine = 6 EndColumn = 8 }) to pynb markdown\n",
"\n",
"[![Script](img/badge-script.svg)](/ConferenceCalls//EarningsClassification.fsx)\u0026emsp;\n",
"[![Notebook](img/badge-notebook.svg)](/ConferenceCalls//EarningsClassification.ipynb)\n",
"\n",
"# Classifying Earnings Calls with Naive Bayes\n",
"\n",
"After dowloading earnings transcripts from Motley Fool, we proceeded to compute \n",
"the Earnings Announcement Return (EAR) of each company\u0027s earnings announcement \n",
"in `EarningsAnnouncementReturn.fsx`. \n",
"\n",
"We can use the EAR of each call as a *proxy* that is meant to measure the market\u0027s \n",
"overall sentiment towards a given earnings call. While a high EAR would indicate \n",
"that the overall market\u0027s sentiment was positive, a low EAR would \n",
"indicate precicely the opposite.\n",
"\n",
"There are many machine learning algorithms to choose from when trying to solve \n",
"a binary or multi-classification problem. Due to its simplicity and intuitive framework, \n",
"a Naive Bayes classifier is often a good place to start.\n",
"\n",
"## Import packages and load scripts\n",
"\n"]
          }
,
          {
           "cell_type": "code",
           "metadata": {},
            "execution_count": 1, "outputs": [], 
           "source": ["open System\n",
"open System.IO\n",
"open FSharp.Data\n",
"Environment.CurrentDirectory \u003c- __SOURCE_DIRECTORY__\n",
"\n",
"#r \"nuget: FSharp.Stats\"\n",
"#r \"nuget: Newtonsoft.Json\"\n",
"#r \"nuget: Plotly.NET, 2.0.0-preview.6\"\n",
"\n",
"#r \"nuget: FSharp.Collections.ParallelSeq, 1.1.4\"\n",
"#load \"Types.fsx\"\n",
"#load \"TextPreprocessing.fsx\"\n",
"\n",
"open Newtonsoft.Json\n",
"open Plotly.NET\n",
"open FSharp.Stats\n",
"open FSharp.Collections.ParallelSeq\n",
"open System.Text.RegularExpressions\n",
"\n",
"open Types\n",
"open Preprocessing.Normalization\n",
"open Preprocessing.Tokenization\n",
"open Preprocessing.NltkData\n"]
          }
,
          {
           "cell_type": "markdown",
           "metadata": {},
           
           "source": ["## Read transcripts from json file\n",
"\n"]
          }
,
          {
           "cell_type": "code",
           "metadata": {},
            "execution_count": 2, "outputs": [
          {
           "data": {
            "text/plain": ["No value returned by any evaluator"]
        },
           "execution_count": 2,
           "metadata": {},
           "output_type": "execute_result"
          }], 
           "source": ["let readEarJson (jsonFile : string) =\n",
"    IO.File.ReadAllText(jsonFile)\n",
"    |\u003e fun json -\u003e JsonConvert.DeserializeObject\u003carray\u003cEarningsAnnouncementReturn\u003e\u003e(json)\n",
"\n",
"let myEars = \n",
"    [\n",
"        \"data-cache/EarningsAnnouncementReturn2018.json\"\n",
"        \"data-cache/EarningsAnnouncementReturn2019.json\"\n",
"        \"data-cache/EarningsAnnouncementReturn2020.json\"\n",
"    ]\n",
"    |\u003e Seq.collect readEarJson\n",
"    |\u003e Seq.choose (fun sample -\u003e \n",
"        match sample.Ear with\n",
"        | Some _ -\u003e Some sample\n",
"        | None -\u003e None)\n",
"    |\u003e Seq.sortBy (fun xs -\u003e xs.EarningsCall.CallId.Date)\n",
"    |\u003e Seq.toArray\n",
"\n",
"myEars.Length\n"]
          }
,
          {
           "cell_type": "markdown",
           "metadata": {},
           
           "source": ["### Data visualization: Earnings Announcement Returns\n",
"\n"]
          }
,
          {
           "cell_type": "code",
           "metadata": {},
            "execution_count": 3, "outputs": [], 
           "source": ["let earsHist (ears : float array) \n",
"             (thresh: float) = \n",
"\n",
"    let obsToPlot name threshExpr =         \n",
"        ears \n",
"        |\u003e Array.filter threshExpr\n",
"        |\u003e fun filteredEars -\u003e\n",
"            let pct = \n",
"                float filteredEars.Length/ float ears.Length \n",
"                |\u003e fun xs -\u003e Math.Round(xs * 100., 2)\n",
"            filteredEars\n",
"            |\u003e Chart.Histogram\n",
"            |\u003e Chart.withTraceName ($\"{name} ({pct}%%)\")\n",
"    [\n",
"        obsToPlot \"Negative\" (fun ret -\u003e ret \u003c= -thresh)\n",
"        obsToPlot \"Neutral\" (fun ret -\u003e abs ret \u003c thresh)\n",
"        obsToPlot \"Positive\" (fun ret -\u003e ret \u003e= thresh)\n",
"    ]\n",
"    |\u003e Chart.Combine\n",
"    |\u003e Chart.withTitle (\"Earnings Announcement Returns (EAR)\")\n",
"    |\u003e Chart.withX_AxisStyle (\"EAR\")\n",
"    |\u003e Chart.withY_AxisStyle (\"Count\")\n",
"    |\u003e Chart.withSize (1000., 500.)\n",
"\n",
"let earsToPlot = \n",
"    myEars\n",
"    |\u003e Array.choose (fun xs -\u003e xs.Ear)\n",
"    // Remove outliers ...\n",
"    |\u003e Array.filter (fun xs -\u003e abs xs \u003c 0.5)\n"]
          }
,
          {
           "cell_type": "code",
           "metadata": {},
            "execution_count": null, "outputs": [
          {
           "data": {
            "text/html": ["\u003cnull\u003e"]
        },
           "execution_count": null,
           "metadata": {},
           "output_type": "execute_result"
          }], 
           "source": ["/// earsHist earsToPlot 0.05 |\u003e Chart.Show \n"]
          }
,
          {
           "cell_type": "markdown",
           "metadata": {},
           
           "source": ["## Generate Dataset\n",
"\n"]
          }
,
          {
           "cell_type": "code",
           "metadata": {},
            "execution_count": 5, "outputs": [], 
           "source": ["let labelEar (earVal : float) thresh : Class = \n",
"    if earVal \u003e= thresh then Positive\n",
"    elif earVal \u003c= -thresh then Negative\n",
"    else Neutral\n",
"\n",
"let trainRaw, testRaw = \n",
"    myEars\n",
"    |\u003e Array.choose (fun xs -\u003e \n",
"        match xs.Ear with\n",
"        | Some ear -\u003e \n",
"            let document = xs.EarningsCall.Transcript |\u003e String.concat(\" \")\n",
"            let label : Class = labelEar ear 0.05\n",
"            if label \u003c\u003e Neutral then Some (document, label)\n",
"            else None\n",
"        | None -\u003e None)\n",
"    |\u003e fun xs -\u003e \n",
"        let cutoff = float xs.Length * 0.8\n",
"        xs.[.. int cutoff], xs.[int cutoff + 1 ..]\n",
"\n",
"trainRaw.Length\n",
"testRaw.Length\n"]
          }
,
          {
           "cell_type": "markdown",
           "metadata": {},
           
           "source": ["#### AdHoc blacklists : \n",
"1. Identifying proper nouns with NLTK database\n",
"2. Fetching company names using requests\n",
"\n"]
          }
,
          {
           "cell_type": "code",
           "metadata": {},
            "execution_count": 6, "outputs": [], 
           "source": ["/// Names\n",
"let nltkNames = \n",
"    System.IO.File.ReadLines(\"data-cache\\NamesNLTK.txt\")\n",
"    |\u003e Seq.map (fun xs -\u003e xs.ToLowerInvariant())\n",
"    |\u003e Set\n"]
          }
,
          {
           "cell_type": "markdown",
           "metadata": {},
           
           "source": ["## Preprocessing Text\n",
"\n",
"#### Tokenize documents\n",
"\n"]
          }
,
          {
           "cell_type": "code",
           "metadata": {},
            "execution_count": 7, "outputs": [], 
           "source": ["// Tokenize all documents\n",
"let tokenizeDocumentWith (nGram : int)\n",
"                         (rawDocument : string) \n",
"                         : Token [] = \n",
"    rawDocument.ToLowerInvariant().Split(\" \")\n",
"    // Blacklist filter\n",
"    |\u003e Array.filter (nltkNames.Contains \u003e\u003e not)\n",
"    |\u003e String.concat(\" \")\n",
"    // Normalize\n",
"    |\u003e getOnlyWords\n",
"    |\u003e expandContractions\n",
"    // Tokenize\n",
"    |\u003e nGrams nGram\n",
"    // Stop words removal\n",
"    |\u003e Array.choose removeStopWords\n",
"    // Empty string removal\n",
"    |\u003e Array.filter (fun xs -\u003e xs.Length \u003c\u003e 0)\n",
"\n",
"let tokenizeDocuments (tokenizer : Tokenizer)\n",
"                      (labelledRawDocuments : (string * Class) []) \n",
"                      : LabelledDocument [] = \n",
"    labelledRawDocuments\n",
"    |\u003e Array.Parallel.map (fun (doc, label) -\u003e \n",
"        tokenizer doc, label)\n"]
          }
,
          {
           "cell_type": "markdown",
           "metadata": {},
           
           "source": ["#### Bag of words representation\n",
"\n"]
          }
,
          {
           "cell_type": "code",
           "metadata": {},
            "execution_count": 8, "outputs": [], 
           "source": ["// Top Tokens from sample\n",
"let getTopNTokens (sampleMaxTokens : int)\n",
"                  (labelledDocuments : LabelledDocument []) \n",
"                  : Set\u003cToken\u003e = \n",
"    labelledDocuments\n",
"    |\u003e Array.collect fst\n",
"    |\u003e Array.countBy id\n",
"    |\u003e Array.sortByDescending snd\n",
"    |\u003e Array.truncate sampleMaxTokens\n",
"    |\u003e Array.map fst\n",
"    |\u003e Set\n",
"\n",
"// Generate bag of words using only top tokens\n",
"let getTopTokenBow (topTokens : Set\u003cToken\u003e)\n",
"                   (document : Document) \n",
"                   : BagOfWords = \n",
"    document\n",
"    |\u003e Array.countBy id\n",
"    |\u003e Array.filter (fun (token, _) -\u003e topTokens.Contains token)\n",
"    |\u003e Array.sortByDescending snd\n",
"\n",
"let generateTopTokenBows (topTokens : Set\u003cToken\u003e)\n",
"                         (labelledDocuments : LabelledDocument []) \n",
"                         : LabelledBagOfWords [] =\n",
"    labelledDocuments\n",
"    |\u003e Array.Parallel.map (fun (doc, label) -\u003e \n",
"        getTopTokenBow topTokens doc, label)\n"]
          }
,
          {
           "cell_type": "markdown",
           "metadata": {},
           
           "source": ["#### Preprocess text\n",
"\n"]
          }
,
          {
           "cell_type": "code",
           "metadata": {},
            "execution_count": 9, "outputs": [], 
           "source": ["type TextVectorizer = \n",
"    { NGram : int \n",
"      MaxSampleTokens : int}\n",
"\n",
"let vectorizeTrainTest (textPreprocessor : TextVectorizer)\n",
"                       (rawDocumentsTrain : (string * Class) []) \n",
"                       (rawDocumentsTest : (string * Class) [])\n",
"                       : LabelledBagOfWords [] * LabelledBagOfWords [] = \n",
"\n",
"    // Tokenize documents (nGrams)\n",
"    let tokenizer = \n",
"        tokenizeDocumentWith textPreprocessor.NGram\n",
"\n",
"    let tokenizedTrain, tokenizedTest = \n",
"        tokenizeDocuments tokenizer rawDocumentsTrain,\n",
"        tokenizeDocuments tokenizer rawDocumentsTest\n",
"   \n",
"    // Generate bag of words using most frequent tokens\n",
"    let topTokens = \n",
"        getTopNTokens textPreprocessor.MaxSampleTokens tokenizedTrain\n",
"    \n",
"    generateTopTokenBows topTokens tokenizedTrain,\n",
"    generateTopTokenBows topTokens tokenizedTest\n"]
          }
,
          {
           "cell_type": "markdown",
           "metadata": {},
           
           "source": ["## Training the Naive Bayes classifier\n",
"\n",
"#### Class Priors\n",
"\n"]
          }
,
          {
           "cell_type": "code",
           "metadata": {},
            "execution_count": 10, "outputs": [], 
           "source": ["let getPriors (labelledBows : LabelledBagOfWords []) \n",
"              : Map\u003cClass, Prior\u003e = \n",
"    \n",
"    let n = labelledBows.Length\n",
"    \n",
"    labelledBows\n",
"    |\u003e Array.groupBy snd\n",
"    |\u003e Array.map (fun (label, labelFreqs) -\u003e \n",
"        let prior =  (float (labelFreqs.Length)/(float n))\n",
"        label, prior)\n",
"    |\u003e Map\n"]
          }
,
          {
           "cell_type": "markdown",
           "metadata": {},
           
           "source": ["#### Aggregate Token Counts by Class -\u003e Class Bag of Words\n",
"\n"]
          }
,
          {
           "cell_type": "code",
           "metadata": {},
            "execution_count": 11, "outputs": [], 
           "source": ["let getClassBagofWords \n",
"    (labelledBow : LabelledBagOfWords [])\n",
"    : (Class * Token * Count) [] = \n",
"    \n",
"    labelledBow\n",
"    |\u003e Array.groupBy snd\n",
"    |\u003e Array.collect (fun (c, classBagOfWords) -\u003e \n",
"        classBagOfWords\n",
"        |\u003e Array.filter (fun (_, label) -\u003e label=c)\n",
"        |\u003e Array.collect fst\n",
"        |\u003e Array.groupBy fst\n",
"        |\u003e Array.map (fun (token, tokenCounts) -\u003e \n",
"            c, token, Array.sumBy snd tokenCounts))\n"]
          }
,
          {
           "cell_type": "markdown",
           "metadata": {},
           
           "source": ["#### Token Likelihoods by Class\n",
"\n"]
          }
,
          {
           "cell_type": "code",
           "metadata": {},
            "execution_count": 12, "outputs": [], 
           "source": ["let computeTokenLikilihoods \n",
"    (classBagOfWords : (Class * Token * Count) [])\n",
"    (vocabN : Count) \n",
"    : (Class * Token * Likelihood) [] = \n",
"    \n",
"    classBagOfWords\n",
"    |\u003e Array.groupBy (fun (_, token, _) -\u003e token)\n",
"    |\u003e Array.collect (fun (_, xs) -\u003e \n",
"        /// Compute total token counts within all classes\n",
"        let totalTokenCounts = \n",
"            xs\n",
"            |\u003e Array.sumBy (fun (_, _, counts) -\u003e counts)\n",
"        /// Compute token likelihood for all classes (Laplace corrected)\n",
"        xs\n",
"        |\u003e Array.map (fun (c, token, counts) -\u003e \n",
"            let tokenLikelihood = \n",
"                float (counts + 1) / float (totalTokenCounts + vocabN)\n",
"            (c, token, tokenLikelihood)))\n",
"\n",
"let getClassLikelihoodsMap (tokenLikelihoods :  (Class * Token * Likelihood) []) \n",
"                           : Map\u003cClass, Map\u003cToken, Likelihood\u003e\u003e = \n",
"    tokenLikelihoods\n",
"    |\u003e Array.groupBy (fun (c, _, _) -\u003e c)\n",
"    |\u003e Array.map (fun (c, xs) -\u003e \n",
"        c, \n",
"        xs\n",
"        |\u003e Array.map (fun (_, token, counts) -\u003e token, counts)\n",
"        |\u003e Map)\n",
"    |\u003e Map\n",
"\n",
"let getTokenLikelihoods (labelledBows : LabelledBagOfWords [])\n",
"                        : Map\u003cClass, Map\u003cToken, Likelihood\u003e\u003e = \n",
"    \n",
"    let classBagOfWords = \n",
"        getClassBagofWords labelledBows\n",
"\n",
"    let vocabN = \n",
"        classBagOfWords\n",
"        |\u003e Array.distinctBy (fun (_, token, _) -\u003e token)\n",
"        |\u003e Array.length\n",
"\n",
"    computeTokenLikilihoods classBagOfWords vocabN\n",
"    |\u003e getClassLikelihoodsMap\n"]
          }
,
          {
           "cell_type": "markdown",
           "metadata": {},
           
           "source": ["#### Building the Naive Bayes Classifier\n",
"\n"]
          }
,
          {
           "cell_type": "code",
           "metadata": {},
            "execution_count": 13, "outputs": [], 
           "source": ["type NbClassifierInfo = \n",
"    { Priors : Map\u003cClass, Prior\u003e\n",
"      Likelihoods : Map\u003cClass, Map\u003cToken, Likelihood\u003e\u003e}\n",
"\n",
"let trainNbClassifier (labelledBows : LabelledBagOfWords []) \n",
"                      : NbClassifierInfo = \n",
"    { Priors = getPriors labelledBows\n",
"      Likelihoods = getTokenLikelihoods labelledBows}\n"]
          }
,
          {
           "cell_type": "markdown",
           "metadata": {},
           
           "source": ["## Classifying new Documents\n",
"\n"]
          }
,
          {
           "cell_type": "code",
           "metadata": {},
            "execution_count": 14, "outputs": [], 
           "source": ["/// Fetch token scores from bag of words\n",
"let getTokenScores \n",
"    (tokenLikelihoods : Map\u003cToken, Likelihood\u003e)\n",
"    (bow : BagOfWords) \n",
"    : TokenScore [] = \n",
"    \n",
"    bow\n",
"    |\u003e Array.choose (fun (token, count) -\u003e \n",
"        match tokenLikelihoods.TryFind token with\n",
"        | Some likelihood -\u003e \n",
"            Some (log (likelihood ** float count))\n",
"        | None -\u003e None)\n",
"\n",
"/// Computes final score by adding token scores, prior\n",
"let computeDocumentScore \n",
"    (prior : Prior)\n",
"    (tokenScores : TokenScore []) \n",
"    : DocumentScore =\n",
"    \n",
"    tokenScores\n",
"    |\u003e Array.fold (+) (log prior)\n",
"\n",
"/// Computes document scores and classifies document\n",
"let classifyBagOfWords \n",
"    (nbClassifierInfo : NbClassifierInfo)\n",
"    (bow : BagOfWords)\n",
"    : Class =\n",
"    \n",
"    nbClassifierInfo.Priors\n",
"    |\u003e Map.toArray\n",
"    |\u003e Array.choose (fun (c, prior) -\u003e \n",
"        match nbClassifierInfo.Likelihoods.TryFind c with\n",
"        | Some tokenLikelihoods -\u003e\n",
"            bow\n",
"            |\u003e getTokenScores tokenLikelihoods  \n",
"            |\u003e computeDocumentScore prior\n",
"            |\u003e fun docScore -\u003e Some (c, docScore)\n",
"        | None -\u003e None)   \n",
"    |\u003e Array.maxBy snd\n",
"    |\u003e fst\n"]
          }
,
          {
           "cell_type": "markdown",
           "metadata": {},
           
           "source": ["### Evaluate\n",
"\n"]
          }
,
          {
           "cell_type": "code",
           "metadata": {},
            "execution_count": 15, "outputs": [], 
           "source": ["let evaluate (nbClassifierInfo : NbClassifierInfo)\n",
"             (labelledBows : LabelledBagOfWords [])\n",
"             : Accuracy =\n",
"    \n",
"    let classifyBow = classifyBagOfWords nbClassifierInfo\n",
"   \n",
"    labelledBows\n",
"    |\u003e PSeq.averageBy (fun (bow, label) -\u003e  \n",
"        if classifyBow bow = label then 1. \n",
"        else 0.)\n"]
          }
,
          {
           "cell_type": "markdown",
           "metadata": {},
           
           "source": ["### Model 1\n",
"\n"]
          }
,
          {
           "cell_type": "code",
           "metadata": {},
            "execution_count": 16, "outputs": [], 
           "source": ["let tp1 = {NGram=2; MaxSampleTokens=5000}\n",
"let trainBow, testBow = vectorizeTrainTest tp1 trainRaw testRaw\n",
"\n",
"let fittedClassifier = trainNbClassifier trainBow\n",
"\n",
"let trainEval = evaluate fittedClassifier trainBow\n",
"let testEval = evaluate fittedClassifier testBow\n"]
          }],
            "metadata": {
            "kernelspec": {"display_name": ".NET (F#)", "language": "F#", "name": ".net-fsharp"},
            "langauge_info": {
        "file_extension": ".fs",
        "mimetype": "text/x-fsharp",
        "name": "C#",
        "pygments_lexer": "fsharp",
        "version": "4.5"
        }
        },
            "nbformat": 4,
            "nbformat_minor": 1
        }
        

